---
title: spocc introduction
author: Scott Chamberlain
date: "2020-07-31"
output: rmarkdown::html_vignette
vignette: >
    %\VignetteIndexEntry{spocc introduction}
    %\VignetteEngine{knitr::rmarkdown}
    %\VignetteEncoding{UTF-8}
---



The rOpenSci projects aims to provide programmatic access to scientific data repositories on the web. A vast majority of the packages in our current suite retrieve some form of biodiversity or taxonomic data. Since several of these datasets have been georeferenced, it provides numerous opportunities for visualizing species distributions, building species distribution maps, and for using it analyses such as species distribution models. In an effort to streamline access to these data, we have developed a package called `spocc`, which provides a unified API to all the biodiversity sources that we provide. The obvious advantage is that a user can interact with a common API and not worry about the nuances in syntax that differ between packages. As more data sources come online, users can access even more data without significant changes to their code. However, it is important to note that spocc will never replicate the full functionality that exists within specific packages. Therefore users with a strong interest in one of the specific data sources listed below would benefit from familiarising themselves with the inner working of the appropriate packages.

## Data Sources

`spocc` currently interfaces with nine major biodiversity repositories

1. [Global Biodiversity Information Facility (GBIF)](https://www.gbif.org/) (via `rgbif`)
GBIF is a government funded open data repository with several partner organizations with the express goal of providing access to data on Earth's biodiversity. The data are made available by a network of member nodes, coordinating information from various participant organizations and government agencies.

2. [Berkeley Ecoengine](https://ecoengine.berkeley.edu/) (via `ecoengine`)
The ecoengine is an open API built by the [Berkeley Initiative for Global Change Biology](https://globalchange.berkeley.edu/). The repository provides access to over 3 million specimens from various Berkeley natural history museums. These data span more than a century and provide access to georeferenced specimens, species checklists, photographs, vegetation surveys and resurveys and a variety of measurements from environmental sensors located at reserves across University of California's natural reserve system.

3. [iNaturalist](https://www.inaturalist.org/)
iNaturalist provides access to crowd sourced citizen science data on species observations.

4. [VertNet](http://vertnet.org/) (via `rvertnet`)
Similar to `rgbif`, ecoengine, and `rbison` (see below), VertNet provides access to more than 80 million vertebrate records spanning a large number of institutions and museums primarly covering four major disciplines (mammology, herpetology, ornithology, and icthyology).

5. Biodiversity Information Serving Our Nation (https://bison.usgs.gov/) (via `rbison`)
Built by the US Geological Survey's core science analytic team, BISON is a portal that provides access to species occurrence data from several participating institutions.

6. [eBird](https://ebird.org/home) (via `rebird`)
ebird is a database developed and maintained by the Cornell Lab of Ornithology and the National Audubon Society. It provides real-time access to checklist data, data on bird abundance and distribution, and communtiy reports from birders.

7. [iDigBio](https://www.idigbio.org/) (via `ridigbio`)
iDigBio facilitates the digitization of biological and paleobiological specimens and their associated data, and houses specimen data, as well as providing their specimen data via RESTful web services.

8. [OBIS](https://obis.org/)
OBIS (Ocean Biogeographic Information System) allows users to search marine species datasets from all of the world's oceans.

9. [Atlas of Living Australia](https://www.ala.org.au/)
ALA (Atlas of Living Australia) contains information on all the known species in Australia aggregated from a wide range of data providers: museums, herbaria, community groups, government departments, individuals and universities; it contains more than 50 million occurrence records.

__Important Note:__ It's important to keep in mind that several data providers interface with many of the above mentioned repositories. This means that occurence data obtained from BISON may be duplicates of data that are also available through GBIF. We do not have a way to resolve these duplicates or overlaps at this time but it is an issue we are hoping to resolve in future versions of the package. See `?spocc_duplicates`, after installation, for more.


## Data retrieval

The most significant function in spocc is the `occ` (short for occurrence) function. `occ` takes a query, often a species name, and searches across all data sources specified in the `from` argument. For example, one can search for all occurrences of [Sharp-shinned Hawks](https://www.allaboutbirds.org/guide/sharp-shinned_hawk/id) (_Accipiter striatus_) from the GBIF database with the following R call.


```r
library('spocc')
(df <- occ(query = 'Accipiter striatus', from = 'gbif'))
#> Searched: gbif
#> Occurrences - Found: 1,092,647, Returned: 500
#> Search type: Scientific
#>   gbif: Accipiter striatus (500)
```

The data returned are part of a `S3` class called `occdat`. This class has slots for each of the data sources described above. One can easily switch the source by changing the `from` parameter in the function call above.

Within each data source is the set of species queried. In the above example, we only asked for occurrence data for one species, but we could have asked for any number. Let's say we asked for data for two species: _Accipiter striatus_, and _Pinus contorta_. Then the structure of the response would be

```
response -- |
            | -- gbif ------- |
                              | -- Accipiter_striatus
                              | -- Pinus_contorta

            | -- ecoengine -- |
                              | -- Accipiter_striatus
                              | -- Pinus_contorta

            ... and so on for each data source

```

If you only request data from gbif, like `from = 'gbif'`, then the other four source slots are present in the response object, but have no data.

You can quickly get just the GBIF data by indexing to it, like


```r
df$gbif
#> Species [Accipiter striatus (500)] 
#> First 10 rows of [Accipiter_striatus]
#> 
#> # A tibble: 500 x 79
#>    name  longitude latitude prov  issues key   scientificName datasetKey
#>    <chr>     <dbl>    <dbl> <chr> <chr>  <chr> <chr>          <chr>     
#>  1 Acci…    -107.      35.1 gbif  cdrou… 2542… Accipiter str… 50c9509d-…
#>  2 Acci…     -90.0     37.1 gbif  cdrou… 2543… Accipiter str… 50c9509d-…
#>  3 Acci…     -99.3     36.5 gbif  cdrou… 2543… Accipiter str… 50c9509d-…
#>  4 Acci…     -76.0     39.6 gbif  cdrou… 2543… Accipiter str… 50c9509d-…
#>  5 Acci…     -73.5     40.7 gbif  gass84 2543… Accipiter str… 50c9509d-…
#>  6 Acci…    -118.      34.6 gbif  cdrou… 2549… Accipiter str… 50c9509d-…
#>  7 Acci…    -121.      36.6 gbif  cdrou… 2550… Accipiter str… 50c9509d-…
#>  8 Acci…     -97.3     27.6 gbif  cdrou… 2550… Accipiter str… 50c9509d-…
#>  9 Acci…     -88.9     30.5 gbif  cdrou… 2550… Accipiter str… 50c9509d-…
#> 10 Acci…     -96.9     33.1 gbif  cdrou… 2550… Accipiter str… 50c9509d-…
#> # … with 490 more rows, and 71 more variables: publishingOrgKey <chr>,
#> #   installationKey <chr>, publishingCountry <chr>, protocol <chr>,
#> #   lastCrawled <chr>, lastParsed <chr>, crawlId <int>, basisOfRecord <chr>,
#> #   taxonKey <int>, kingdomKey <int>, phylumKey <int>, classKey <int>,
#> #   orderKey <int>, familyKey <int>, genusKey <int>, speciesKey <int>,
#> #   acceptedTaxonKey <int>, acceptedScientificName <chr>, kingdom <chr>,
#> #   phylum <chr>, order <chr>, family <chr>, genus <chr>, species <chr>,
#> #   genericName <chr>, specificEpithet <chr>, taxonRank <chr>,
#> #   taxonomicStatus <chr>, dateIdentified <chr>,
#> #   coordinateUncertaintyInMeters <dbl>, stateProvince <chr>, year <int>,
#> #   month <int>, day <int>, eventDate <date>, modified <chr>,
#> #   lastInterpreted <chr>, references <chr>, license <chr>,
#> #   geodeticDatum <chr>, class <chr>, countryCode <chr>, recordedByIDs <list>,
#> #   identifiedByIDs <list>, country <chr>, rightsHolder <chr>,
#> #   identifier <chr>, `http://unknown.org/nick` <chr>, verbatimEventDate <chr>,
#> #   datasetName <chr>, collectionCode <chr>, verbatimLocality <chr>,
#> #   gbifID <chr>, occurrenceID <chr>, taxonID <chr>, catalogNumber <chr>,
#> #   recordedBy <chr>, `http://unknown.org/occurrenceDetails` <chr>,
#> #   institutionCode <chr>, rights <chr>, eventTime <chr>, identifiedBy <chr>,
#> #   identificationID <chr>, informationWithheld <chr>, occurrenceRemarks <chr>,
#> #   identificationRemarks <chr>, infraspecificEpithet <chr>,
#> #   individualCount <int>, vernacularName <chr>, locality <chr>, county <chr>
```

When you get data from multiple providers, the fields returned are slightly different because each data provider uses different formats for their data; different arrangements of data and different variable names for the same thing (e.g., one data provider may call latitude "latitude", while another may call it "lat"). For example:


```r
df <- occ(query = 'Accipiter striatus', from = c('gbif', 'ecoengine'), limit = 25)
df$gbif$data$Accipiter_striatus
#> # A tibble: 25 x 73
#>    name  longitude latitude issues prov  key   scientificName datasetKey
#>    <chr>     <dbl>    <dbl> <chr>  <chr> <chr> <chr>          <chr>     
#>  1 Acci…    -107.      35.1 cdrou… gbif  2542… Accipiter str… 50c9509d-…
#>  2 Acci…     -90.0     37.1 cdrou… gbif  2543… Accipiter str… 50c9509d-…
#>  3 Acci…     -99.3     36.5 cdrou… gbif  2543… Accipiter str… 50c9509d-…
#>  4 Acci…     -76.0     39.6 cdrou… gbif  2543… Accipiter str… 50c9509d-…
#>  5 Acci…     -73.5     40.7 gass84 gbif  2543… Accipiter str… 50c9509d-…
#>  6 Acci…    -118.      34.6 cdrou… gbif  2549… Accipiter str… 50c9509d-…
#>  7 Acci…    -121.      36.6 cdrou… gbif  2550… Accipiter str… 50c9509d-…
#>  8 Acci…     -97.3     27.6 cdrou… gbif  2550… Accipiter str… 50c9509d-…
#>  9 Acci…     -88.9     30.5 cdrou… gbif  2550… Accipiter str… 50c9509d-…
#> 10 Acci…     -96.9     33.1 cdrou… gbif  2550… Accipiter str… 50c9509d-…
#> # … with 15 more rows, and 65 more variables: publishingOrgKey <chr>,
#> #   installationKey <chr>, publishingCountry <chr>, protocol <chr>,
#> #   lastCrawled <chr>, lastParsed <chr>, crawlId <int>, basisOfRecord <chr>,
#> #   taxonKey <int>, kingdomKey <int>, phylumKey <int>, classKey <int>,
#> #   orderKey <int>, familyKey <int>, genusKey <int>, speciesKey <int>,
#> #   acceptedTaxonKey <int>, acceptedScientificName <chr>, kingdom <chr>,
#> #   phylum <chr>, order <chr>, family <chr>, genus <chr>, species <chr>,
#> #   genericName <chr>, specificEpithet <chr>, taxonRank <chr>,
#> #   taxonomicStatus <chr>, dateIdentified <chr>,
#> #   coordinateUncertaintyInMeters <dbl>, stateProvince <chr>, year <int>,
#> #   month <int>, day <int>, eventDate <date>, modified <chr>,
#> #   lastInterpreted <chr>, references <chr>, license <chr>,
#> #   geodeticDatum <chr>, class <chr>, countryCode <chr>, recordedByIDs <list>,
#> #   identifiedByIDs <list>, country <chr>, rightsHolder <chr>,
#> #   identifier <chr>, `http://unknown.org/nick` <chr>, verbatimEventDate <chr>,
#> #   datasetName <chr>, collectionCode <chr>, verbatimLocality <chr>,
#> #   gbifID <chr>, occurrenceID <chr>, taxonID <chr>, catalogNumber <chr>,
#> #   recordedBy <chr>, `http://unknown.org/occurrenceDetails` <chr>,
#> #   institutionCode <chr>, rights <chr>, eventTime <chr>, identifiedBy <chr>,
#> #   identificationID <chr>, informationWithheld <chr>, occurrenceRemarks <chr>
df$ecoengine$data$Accipiter_striatus
#> # A tibble: 25 x 17
#>    longitude latitude url   key   observation_type name  country state_province
#>        <dbl>    <dbl> <chr> <chr> <chr>            <chr> <chr>   <chr>         
#>  1     -115.     33.4 http… MVZ:… specimen         Acci… United… California    
#>  2     -117.     34.5 http… MVZ:… specimen         Acci… United… California    
#>  3     -116.     33.9 http… MVZ:… specimen         Acci… United… California    
#>  4     -115.     33.4 http… MVZ:… specimen         Acci… United… California    
#>  5     -114.     34.5 http… MVZ:… specimen         Acci… United… California    
#>  6     -119.     41.7 http… MVZ:… specimen         Acci… United… Nevada        
#>  7     -119.     39.4 http… MVZ:… specimen         Acci… United… Nevada        
#>  8     -119.     39.4 http… MVZ:… specimen         Acci… United… Nevada        
#>  9     -116.     40.1 http… MVZ:… specimen         Acci… United… Nevada        
#> 10     -116.     40.1 http… MVZ:… specimen         Acci… United… Nevada        
#> # … with 15 more rows, and 9 more variables: begin_date <date>, end_date <chr>,
#> #   source <chr>, remote_resource <chr>, locality <chr>,
#> #   coordinate_uncertainty_in_meters <int>, recorded_by <chr>,
#> #   last_modified <chr>, prov <chr>
```

We provide a function `occ2df` that pulls out a few key columns needed for making maps:


```r
occ2df(df)
#> # A tibble: 50 x 6
#>    name                            longitude latitude prov  date       key      
#>    <chr>                               <dbl>    <dbl> <chr> <date>     <chr>    
#>  1 Accipiter striatus Vieillot, 1…    -107.      35.1 gbif  2020-01-02 25429665…
#>  2 Accipiter striatus Vieillot, 1…     -90.0     37.1 gbif  2020-01-01 25430843…
#>  3 Accipiter striatus Vieillot, 1…     -99.3     36.5 gbif  2020-01-01 25430853…
#>  4 Accipiter striatus Vieillot, 1…     -76.0     39.6 gbif  2020-01-01 25430927…
#>  5 Accipiter striatus Vieillot, 1…     -73.5     40.7 gbif  2020-01-01 25430953…
#>  6 Accipiter striatus Vieillot, 1…    -118.      34.6 gbif  2020-01-03 25499936…
#>  7 Accipiter striatus Vieillot, 1…    -121.      36.6 gbif  2020-01-04 25500018…
#>  8 Accipiter striatus Vieillot, 1…     -97.3     27.6 gbif  2020-01-04 25500046…
#>  9 Accipiter striatus Vieillot, 1…     -88.9     30.5 gbif  2020-01-04 25500173…
#> 10 Accipiter striatus Vieillot, 1…     -96.9     33.1 gbif  2020-01-05 25500177…
#> # … with 40 more rows
```

`occ2df()` not only combines data into a single data.frame, but it also standardizes the key columns (name, longitude, latitude, prov (provider), date, and key (occurrence key)). Note that you can look up the exact occurrence with the data provider using the `key` value.

### Standardized parameters

Each data source has a variety of different ways, or parameters, to use to search its data. Some of the parameters are the same across data sources. In `occ()` we've attempted to surface those similar parameters so you can have a single way to define a parameter and it gets applied to every data source. This way you don't have to know the vagaries of each data source, what formatting they expect, etc.

The standardized parameters in `occ()` are:

- query: a scientific taxon name
- limit: number of records to retrieve
- start: page number to start at
- page: page number to retrieve
- geometry: a "spatial filter" - bounding box, well known text, or an sp or sf polygon or multipolygon
- has_coords: exclude records without latitude/longitude data
- date: a date range

However, not all parameters across data sources are able to be standardized, so you can pass data source specific parameters to their matching parameter name, e.g., pass GBIF parameters to `gbifopts` and ALA parameters to `alaopts`. 


## Clean up taxonomic names

See the vignette [cleaning names](https://docs.ropensci.org/spocc/articles/fixnames)

## Clean data

All data cleaning functionality is in a new package [scrubr](https://github.com/ropensci/scrubr). [On CRAN](https://cran.r-project.org/package=scrubr).

## Make maps

All mapping functionality is now in a separate package [mapr](https://github.com/ropensci/mapr) (formerly known as `spoccutils`), to make `spocc` easier to maintain. [On CRAN](https://cran.r-project.org/package=mapr).
